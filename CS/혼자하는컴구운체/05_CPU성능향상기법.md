# 5-1 빠른 CPU를 위한 설계 기법

**클럭**, **멀티코어**, **멀티스레드**에 대해 알아보고,

이들과 CPU 속도와의 관계를 알아본다.

## 클럭

이전 장에서 배웠던 것을 복습하자면,

- 컴퓨터 부품들은 **클럭 신호**에 맞춰 움직인다.
- CPU는 **명령어 사이클**이라는 정해진 흐름에 맞춰 명령어들을 실행한다.

그러면, 클럭 신호가 빠르게 반복되면 CPU는 그만큼 빠른 박자에 맞춰 움직인다.

→ 이로 인해 클럭 속도는 CPU 속도 단위로 간주되기도 한다.

**클럭 속도**는 **헤르츠(Hz)** 단위로 측정한다. 1초에 클럭이 몇 번 반복되는지를 나타낸다.

실제 CPU 클럭 속도는 2.5G(25억)Hz ~ 4.9G(49억)Hz 정도 된다고 한다.

그러나, 클럭 속도는 매번 일정하지 않다.

고성능을 요하는 순간에는 순간적으로 클럭 속도를 높이고, 유연하게 속도를 낮추기도 한다.

최대 클럭 속도를 강제로 더 끌어올리는 것을 **오버클럭킹(overclocking)**이라고 한다.

또한, 클럭 속도를 무조건 높인다고 CPU가 빨라지는 것은 아니다.

→ 클럭 속도를 무작정 올리면 **발열 문제**가 발생할 수 있다.

- **❓ 그래도 오버클럭을 사용하고 싶다! 그럼 어떻게 할까?**
    - **고성능 쿨러 (공냉식 < 수냉식)**
    - **전압 낮추기**
    - **열 전도체와 써멀 페이스트**
        
        → CPU나 GPU와 쿨러 사이에 사용되는 열 전도체로, **열 전달 효율을 높여주는 역할**을 함. 고성능의 써멀 페이스트를 사용하면 열을 더 효율적으로 방출할 수 있어.
        
        **→ 써멀 페이스트의 도포**가 적절하지 않으면 열 전도가 잘 되지 않아서 발열 문제를 해결하기 어려울 수 있으므로, **정확하게 도포**하는 것이 중요함.
        
    
    등등이 있지만,
    
    시스템 안정성을 위해, 성능을 높이려는 욕심을 덜어내는 것도 중요하겠다!
    

## 코어와 멀티코어

CPU의 코어와 스레드 수를 늘리는 방법으로 CPU의 성능을 높일 수 있다.

### 코어를 늘리는 방법

<aside>

**코어**

전통적인 관점에서 명령어를 실행하는 부품(CPU)은 하나만 존재했다.

하지만 기술적 발전을 통해 CPU 내부에는 명령어를 실행하는 부품은 얼마든지 만들 수 있게 되었다.

CPU 내부에 **여러 개의 명령어를 실행하는 부품**들을 **코어**라고 한다.

→ CPU는 **명령어를 실행하는 부품을 여러 개 포함하는 부품**이다. 

→ 이런 CPU를 **멀티코어 CPU, 멀티코어 프로세서**라고 부릅니다.

</aside>

멀티 코어의 처리 속도는 단일 코어보다 더 빠르다.

*ex) 클럭 속도 2.4 GHz, 단일 코어 vs 클럭 속도 1.9GHz, 멀티 코어* → 후자의 성능이 더 좋다.

코어의 개수에 따라 아래와 같이 부르게 된다.

*싱글, 듀얼, 트리플, 쿼드, 헥사, 옥타, 데카, 도데카 …*

그러나, 코어 수에 비례하여 CPU의 연산 속도가 증가하지만은 않는다.

→ 코어마다 처리할 연산이 적절히 분배 되지 않는다면 코어 수에 비례하여 연산 속도가 증가하지 않는다.

→ 코어가 지나치게 많아도 성능에는 크게 영향이 없다.

중요한 것은, **코어마다 처리할 명령어들을 얼마나 적절하게 분배하느냐**이다.

## 스레드와 멀티스레드

<aside>

**스레드**

사전적 의미는 ‘실행 흐름의 단위’

그러나, CPU에서 사용되는 스레드와 프로그래밍에서 사용되는 스레드는 다르다.

→ **하드웨어적 스레드**, **소프트웨어적 스레드**

</aside>

- **하드웨어적 스레드**
    
    하나의 코어가 동시에 처리하는 명령어 단위
    
    하나의 코어로 여러 명령어를 동시에 처리하는 CPU를 **멀티스레드 프로세서, 멀티스레드 CPU** 라고 한다.
    
    *ex) 8코어 16스레드*
    
    → 명령어를 실행하는 부품 여덟 개 포함, 한 번에 열여섯 개 명령어 처리 가능
    
    → 코어당 두 개의 하드웨어 스레드를 처리할 수 있다는 뜻으로 볼 수 있음
    
    <aside>
    
    **하이퍼스레딩**
    
    인텔의 멀티스레드 기술
    
    </aside>
    
- **소프트웨어적 스레드**
    
    하나의 프로그램에서 독립적으로 실행되는 단위
    
    프로그램은 실행되는 과정에서 한 부분만 실행될 수도, 여러 부분이 동시에 실행될 수도 있다.
    
    → **싱글스레드, 멀티스레드**
    
    *ex) 워드 프로세서 프로그램을 개발할 때*
    
    → 입력 받은 내용을 화면에 보여주는 기능 + 입력한 내용 맞춤법 검사 + 수시로 저장
    
    → 이 기능들이 동시에 진행되려면 각각의 스레드로 만들면 된다.
    

### 멀티스레드 프로세서

**하나의 코어로 여러 명령어를 동시에 처리하는 기술**

큰 핵심은 레지스터.

*프로그램 카운터, 스택 포인터, 메모리 버퍼 레지스터, 메모리 주소 레지스터…*

이렇게 하나의 명령어를 처리하기 위해 꼭 **필요한 레지스터를 여러 개 가지고 있음 된다.**

메모리 속 프로그램 입장에서는,

하드웨어 스레드는 마치 ‘한 번에 하나의 명령어를 처리하는 CPU’와 같다.

*ex) 실제 CPU가 2코어 4스레드라면, 프로그램 입장에서는 CPU가 4개가 있는 것처럼 보인다.*

→ 그래서 하드웨어 스레드를 **논리 프로세서**라고 부르기도 한다.

→ [작업 관리자]-[성능]-[CPU] 탭 에서 확인할 수 있다.

- ❓ **CPU가 멀티스레드, 파이프라이닝을 지원해도 GPU보다 느릴까?**
    
    **GPU는 엄청나게 많은 코어를 가지고 있다.**
    
    멀티스레드, 파이프라이닝이 CPU의 명령어 처리 속도에 도움을 주지만, GPU의 수많은 코어 및 뛰어난 병렬 처리보다 속도가 빠르지 않다.
    
    GPU는 수천 개의 코어가 동시에 작업을 처리할 수 있기 때문에 **대규모 병렬 처리**에서는 훨씬 더 효율적이다. 반면, CPU는 멀티코어를 사용하더라도 코어의 수가 상대적으로 적고, 병렬 처리에서 GPU만큼 효율적으로 작업을 분산할 수 없다.
    
    또한 CPU는 다양한 작업을 순차적으로 처리할 수 있지만, **병렬로 동일한 작업을 반복적으로 처리하는 데는 한계**가 있다. 따라서 GPU가 처리하는 대규모 병렬 연산에서는 성능 차이가 크게 나게 된다.
    
    CPU와 GPU의 역할과 핵심을 아래와 같이 Chat-GPT를 통해 알 수 있었다. 
    
    <aside>
    
    ### . **CPU 멀티코어**:
    
    - **목적**: CPU는 주로 범용적인 계산을 처리하는 장치야. 즉, 다양한 종류의 작업을 처리할 수 있도록 설계돼 있어.
    - **코어 수**: 멀티코어 CPU는 여러 개의 코어를 가지고 있지만, 각 코어는 상대적으로 적은 수의 스레드를 처리할 수 있어. 예를 들어, 4코어 CPU는 한 번에 4개의 작업을 처리할 수 있지.
    - **작업 처리**: CPU는 각 작업을 순차적으로, 또는 동시에 처리할 수 있도록 최적화돼 있어. 복잡한 연산, 조건 분기, 시스템 명령어 등 다양한 작업을 동시에 빠르게 처리할 수 있는 능력이 있어.
    - **설계**: CPU의 코어는 각각 높은 클럭 속도(GHz)로 동작하며, 매우 정교한 명령어를 실행할 수 있도록 설계돼 있어.
    
    ### 2. **GPU**:
    
    - **목적**: GPU는 주로 **병렬 처리**를 전문으로 하는 장치야. 특히, 수천 개의 작은 코어를 사용해 대량의 데이터를 동시에 처리하는 데 강점을 가져.
    - **코어 수**: GPU는 CPU보다 훨씬 많은 수의 코어를 가지고 있어. 예를 들어, 고급 GPU는 수천 개의 코어를 가지며, 각 코어는 매우 단순한 작업을 처리하는 데 특화돼 있어.
    - **작업 처리**: GPU는 반복적이고 병렬적으로 처리할 수 있는 작업에 매우 강해. 예를 들어, 그래픽 렌더링, 행렬 연산, 머신러닝 같은 대량의 데이터를 동시에 처리해야 하는 작업에 효율적이야.
    - **설계**: GPU의 코어는 비교적 낮은 클럭 속도로 동작하지만, 동시에 많은 양의 연산을 병렬로 처리할 수 있도록 설계돼 있어.
    
    ### 핵심 차이점:
    
    - **작업의 성격**: CPU는 **다양한 작업을 처리**하는 데 강하고, GPU는 **병렬 작업**을 효율적으로 처리하는 데 강해.
    - **병렬 처리**: CPU는 적은 수의 코어로 여러 종류의 작업을 빠르게 처리하지만, GPU는 수많은 코어로 같은 종류의 작업을 동시에 처리하는 데 특화돼.
    - **클럭 속도와 처리 능력**: CPU는 빠른 클럭 속도로 빠른 계산을 수행하는 데 강하고, GPU는 많은 코어를 사용하여 대량의 데이터를 동시에 처리하는 데 유리해.
    
    ### 예시:
    
    - **CPU 멀티코어**: 웹 브라우징, 이메일 체크, 문서 작성과 같은 작업은 CPU의 멀티코어로 처리하는 게 적합해.
    - **GPU**: 비디오 게임 렌더링, 머신러닝 모델 학습, 고해상도 이미지 처리 등 대규모 병렬 연산이 필요한 작업은 GPU에서 훨씬 더 효율적으로 처리할 수 있어.
    </aside>
    

# 5-2 명령어 병렬 처리 기법

CPU가 시간을 효율적으로 쓰면서 작동하게 만드는 것도 중요하다.

**명령어 병렬 처리 기법**을 알아보고,

대표적인 명령어 병렬 처리 기법인 **명령어 파이프라이닝**, **슈퍼스칼라**, **비순차적 명령어 처리** 를 배운다.

## 명령어 파이프라인

**명령어 처리 과정**을 클럭 단위로 나누면 아래와 같다.

1. 명령어 인출(Instruction Fetch)
2. 명령어 해석(Instruction Decode)
3. 명령어 실행(Execute Instruction)
4. 결과 저장(Write Back)

*~~전공 책마다 다를 수 있다.~~*

같은 단계가 겹치지만 않는다면, CPU는 각 단계를 동시에 실행할 수 있다.

*ex) 한 명령어를 ‘인출’하는 동안, 다른 명령어를 ‘실행’할 수 있다.*

→ 명령어를 하나하나 실행하는 것보다 훨씬 더 효율적으로 처리할 수 있다.

→ 명령어들을 **명령어 파이프라인**에 넣고 동시에 처리하는 기법을 **명령어 파이프라이닝**이라고 한다.

그러나 특정 상황에서는 성능 향상에 실패하는 경우도 있다.

- **데이터 위험**
    
    명령어 간 ‘**데이터 의존성**’에 의해 발생된다.
    
    어떤 명령어는 이전 명령어를 끝까지 실행해야만 비로소 실행할 수 있는 경우가 있다.
    
    ![image.png](attachment:9d5824b8-fce3-4c1c-8bbf-b0d715be0c66:image.png)
    
- **제어 위험**
    
    분기 등으로 인한 ‘**프로그램 카운터의 갑작스러운 변화**’에 의해 발생한다.
    
    프로그램 카운터는 현재 실행 중인 명령어의 다음 주소로 갱신되지만,
    
    실행 흐름이 바뀌어 프로그램 카운터 값에 갑작스러운 변화가 생길 수 있다.
    
    이 때 명령어 파이프라인에 미리 가지고 와서 처리 중이었던 명령어들은 쓸모 없어진다.
    
    → 프로그램이 어디로 분기할지 미리 예측한 후 그 주소를 인출하는 기술인 **분기 예측**을 이용해 이를 방지하기도 한다.
    
    - **❓ 분기 예측의 종류**
        
        <aside>
        
        - **고정 분기 예측 (Fixed Branch Prediction)**:
            - 가장 단순한 방법으로, CPU가 항상 같은 경로를 예측한다. 예를 들어, 항상 분기 `True`를 예측하는 방식이다.
        - **동적 분기 예측 (Dynamic Branch Prediction)**:
            - **히스토리 기반 예측**: 분기 예측기가 이전에 분기가 어떻게 실행되었는지에 대한 정보를 바탕으로 예측을 수행한다. 예를 들어, **2비트 예측기**는 이전 분기 결과를 2비트 상태로 저장하여, 그 상태에 따라 분기를 예측한다.
            - **지점 예측**: **지점 예측기**는 각 분기 지점마다 분기가 발생할 가능성을 기록하여, 이를 기반으로 예측을 수행한다.
        - **다중 분기 예측 (Multiple Branch Prediction)**:
            - 한 번에 여러 개의 분기 명령어를 예측하는 방법이다. 여러 분기 명령어를 동시에 예측하여 병렬로 처리할 수 있다.
        </aside>
        
        **분기 예측**은 **조건문** 또는 **분기 명령어**의 실행 경로를 미리 예측하여 파이프라인 효율성을 극대화하는 중요한 기술이다.
        
        **동적 예측**을 활용하면, 프로그램 흐름을 미리 예측하고, 예측이 맞을 경우 성능을 크게 향상시킬 수 있습니다.
        
        분기 예측의 실패는 성능 저하를 초래할 수 있지만, 이를 보완하기 위한 다양한 예측 기법들이 현대 프로세서에 적용되고 있습니다.
        
    
    ![image.png](attachment:d92a1ef5-2b0f-436e-8ed1-048493e06b8a:image.png)
    
- **구조적 위험**
    
    **자원 위험**이라고도 부름.
    
    명령어들을 실행하는 과정에서 서로 다른 명령어가 동시에 ALU, 레지스터 등을 사용하려고 할 때 발생한다.
    

## 슈퍼스칼라

대부분의 CPU에서는 여러 개의 파이프라인을 이용한다.

<aside>

**슈퍼스칼라**

CPU 내부에 여러 개의 명령어 파이프라인을 포함한 구조

*ex) 공장 생산 라인을 여러 개 두는 것과 비슷한 구조임.*

</aside>

- 이것이 가능한 CPU를 **슈퍼스칼라 프로세서, 슈퍼스칼라 CPU**라고 한다.
    
    → 멀티스레드 프로세서는 한 번에 여러 명령어를 인출하고, 해석하고, 실행할 수 있기 때문에 슈퍼 스칼라 구조를 사용할 수 있다.
    
- 이론상 파이프라인 개수에 비례하여 프로그램 처리 속도가 빨라지지만, 실제로 예상치 못한 문제가 발생하여 그렇지 않을 경우가 있다.
    
    → 파이프라인이 많을 수록 파이프 라인 위험도가 높아지고, 이를 방지하기 위해 고도로 설계되어야 한다.
    

## 비순차적 명령어 처리

<aside>

**Out-of-order execution (OoOE)**

오늘날 CPU 성능 향상에 크게 기여한 기법이자 대부분의 CPU가 차용하는 기법.

</aside>

명령어 파이프라이닝, 슈퍼스칼라 기법은 명령어의 순차적인 처리를 상정한 방법.

→ 예상치 못한 문제들로 인해 곧바로 처리되지 못하기도 한다.

- **비순차적 명령어 처리 활용 예시**
    
    ![image.png](attachment:7b462f71-1535-428b-972f-9f13f57a3e07:image.png)
    
    3번 명령어는 데이터 위험을 방지하기 위해, 1번과 2번이 실행되기까지 기다려야 한다.
    
    그러면 파이프라인은 아래와 같이 표현될 수 있다.
    
    ![image.png](attachment:0902ad99-8c87-4acd-b64e-e9e572962ba6:image.png)
    
    그런데 뒤에 있는 4, 5, 6번 명령어들도 기다려야 할 필요가 있을까?
    
    3번 명령어보다 먼저 실행하여 파이프라인으로 실행될 수 있지 않을까?
    
    이를 적용하면 아래와 같이 파이프라인을 표현할 수 있다.
    
    ![image.png](attachment:ffb47258-2803-4599-ad19-a593ff820cdd:image.png)
    

**순서를 바꿔 실행해도 무방한 명령어를 먼저 실행하여 파이프라인이 멈추는 것을 방지**하는 기법을 **비순차적 명령어 처리 기법**이라고 한다.

비순차적 명령어 처리가 가능한 CPU는 명령어들이 어떤 명령어와 데이터 의존성을 가지고 있는지, 순서를 바꿔 실행할 수 있는 명령어에는 어떤 것들이 있는지를 판단할 수 있어야 한다.

# 5-3 CISC와 RISC

명령어 파이프라이닝과 슈퍼스칼라 기법을 실제로 CPU에 적용하려면 명령어가 파이프라이닝에 최적화되어 있어야 한다.

파이프라이닝 하기 쉬운 명령어를 알아보기 위해 CPU의 언어인 **ISA**와 다른 성격의 ISA를 기반으로 설계된 **CISC**와 **RISC**를 학습한다.

## 명령어 집합

CPU는 종류에 따라 명령어의 형태가 세세하게 다르다.

*명령어의 생김새, 할 수 있는 연산, 주소 지정 방식 등…*

<aside>

**ISA (Instruction Set Architecture) ; 명령어 집합, 명령어 집합 구조**

CPU가 이해할 수 있는 명령어들의 모음

</aside>

*ex) 인텔 노트북 (x86, x86-64 ISA), 애플 아이폰 (ARM ISA)는 서로의 명령어를 이해할 수 없다.* 

ISA가 다르다는 것은 CPU가 이해할 수 있는 명령어가 다르고, 어셈블리어도 달라진다.

→ 같은 소스 코드로 만들어진 프로그램이라 할지라도 ISA가 다르면 CPU가 이해할 수 있는 명령어, 어셈블리어도 달라진다.

![image.png](attachment:5c3bf932-888c-4d27-8538-7a5f34f51f70:image.png)

이렇게 보면, ISA는 일종의 CPU의 언어와 같다.

→ ISA가 다르면 제어장치가 명령어를 해석하는 방식, 사용되는 레지스터의 종류와 개수, 메모리 관리 방법, CPU 하디웨어 설계 등에 큰 변화와 영향을 준다.

→ ISA는 CPU를 비롯한 하드웨어가 소프트웨어를 어떻게 이해할 지에 대한 약속이다.

→ 파이프라인, 슈퍼스칼라, 비순차적 명령어 처리를 사용하기 유리한 ISA, 그렇지 못한 ISA도 존재할 수 있다.

→ 명령어 병렬 처리 기법에 유리한 ISA는 **CISC**와 **RISC**가 있다.

## CISC

<aside>

**CISC (Complex Instruction Set Computer)**

복잡한 명령어 집합을 활용하는 컴퓨터(CPU)

복잡하고 다양한 기능을 제공하는 명령어 집합을 사용한다.

*ex) x86, x86-64*

</aside>

- CISC는 명령어의 형태와 크기가 다양한 **가변 길이 명령어**를 활용한다.
- 적은 수의 명령어로도 프로그램을 실행할 수 있다.
    
    *※ 같은 소스 코드를 컴파일해도 CPU마다 생성되는 실행 파일의 크기가 다를 수 있다.*
    
    → 이러한 점은 **메모리 공간을 절약한다**는 장점이 있다.
    

CISC의 치명적인 단점은,

- **명령어가 복잡하고, 명령어의 크기와 실행되기까지의 시간이 일정하지 않다.**
    
    명령어 하나를 실행하는 데에 여러 클럭 주기를 필요로 한다.
    
    → 이는 명령어 (각 단계에 소요되는 시간이 일정한)**파이프라인을 구현하는 데 큰 문제**가 된다.
    
    → 명령어 파이프라인이 제대로 동작하지 않는다는 것은 현대 CPU 기술에서 치명적인 문제이다.
    
    ![image.png](attachment:b1e16996-09ff-4542-8525-2ff465ef82d6:image.png)
    
- 게다가 대다수의 복잡한 명령어들의 사용 빈도가 낮다. 자주 사용되는 명령어만 쓰인다.

## RISC

CISC의 단점을 보완하기 위해서는,

1. 빠른 처리를 위해 명령어 파이프라인을 활용해야 한다. → **명령어 길이와 수행 시간이 짧고 규격화**되어 있어야 한다.
2. 자주 쓰인 명령어만 줄곧 사용하니, **기본적인 명령어를 작고 빠르게 만드는 것이 중요**하다.

를 해결해야 한다.

<aside>

**RISC (Reduced Instruction Set Computer)**

CISC와는 달리 짧고 규격화된 명령어, 되도록 1클럭 내외로 실행되는 명령어를 지향한다.

*ex) ARM*

</aside>

- RISC는 **고정 길이 명령어**를 사용한다.
    
    → 명령어 파이프라이닝에 최적화되어 있다.
    
- 메모리에 직접 접근하는 명령어를 `load` `store` 두 개로 제한할 만큼 **단순화, 최소화를 추구**한다.
    
    → **load-store 구조**
    
- RISC는 레지스터를 적극적으로 활용한다.
    
    → CISC보다 레지스터를 이용하는 연산이 많고, 범용 레지스터 개수도 더 많다.
    
    → 사용 가능한 명령어 개수가 CISC보다 적기 때문에 RISC는 CISC보다 많은 명령으로 프로그램을 작동시킨다.
    

CISC와 RISC의 차이를 정리하면 아래와 같다.

| CISC | RISC |
| --- | --- |
| 복잡하고 다양한 명령어 | 단순하고 적은 명령어 |
| 가변 길이 명령어 | 고정 길이 명령어 |
| 다양한 주소 지정 방식 | 적은 주소 지정 방식 |
| 프로그램을 이루는 명령어의 수가 적음 | 프로그램을 이루는 명령어의 수가 많음 |
| 여러 클럭에 걸쳐 명령어 수행 | 1클럭 내외로 명령어 수행 |
| 파이프라이닝하기 어려움 | 파이프라이닝하기 쉬움 |
- **❓ x86은 아직까지 CISC를 사용하고 있는건가?**
    
    그렇다. 하지만 현재 x86은 RISC와 혼합되어 있다.
    
    CISC는 아직까지도 널리 사용되고 있는데,
    
    그 이유는 많은 소프트웨어와 하드웨어가 **오랜 기간 호환되도록** 설계되어 있기 때문에, 기존의 소프트웨어를 그대로 사용할 수 있다는 점에서 **호환성**이 중요한 환경에서는 계속 사용되고 있다.
    
    또한, 다양한 주소 지정 방식과 복잡한 명령어를 지원하며,
    
    **여러 연산을 하나의 명령어로 처리할 수 있는 기능**을 갖추고 있다.
    
    *ex)  `MOV` 명령어는 데이터를 메모리에서 레지스터로 옮기고, 그 과정에서 주소 계산을 수행하는 등의 다양한 기능을 한 번에 처리할 수 있다.*
    
    그리고 x86은 현재 CISC와 RISC가 혼합되어 있다. 명령어를 내부적으로 RISC로 변환하여 처리하기 때문에, 파이프라이닝, 슈퍼스칼라 등이 가능해지면서 성능이 높다.
    
- ❓ **RISC-V에 대해서**
    
    RISC 아키텍처 중에서 가장 주목 받고 있다.
    
    RISC 아키텍처는 위에서 언급한 ARM, POWER(IBM) 등 다양하게 존재한다.
    
    그 중 RISC-V는, 오픈 소스를 기반으로 하는 RISC 아키텍처이다.
    
    그러므로 누구나 수정할 수 있고, 확장할 수 있는 구조를 갖고 있다.
    
    연구 기관, 교육 기관이 자유롭게 RISC-V를 사용하고 커스터마이즈할 수 있으며,
    
    이러한 특성 덕분에 **임베디드 시스템**, **IoT**, **고성능 컴퓨팅**, **인공지능** 등 다양한 분야에서 점점 더 많이 채택되고 있다.